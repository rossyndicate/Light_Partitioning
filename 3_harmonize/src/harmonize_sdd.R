
harmonize_sdd <- function(raw_sdd, p_codes,
                          sdd_analytical_method_matchup,
                          sdd_sample_method_matchup,
                          sdd_equipment_matchup){
  
  # Minor data prep ---------------------------------------------------------
  
  # First step is to read in the data and do basic formatting and filtering
  raw_sdd <- raw_sdd %>%
    left_join(x = ., y = p_codes, by = "parm_cd") %>%
    # Remove trailing white space in labels (Is this still necessary?)
    filter(
      media %in% c("Water", "water")) %>%
    # Add an index to control for cases where there's not enough identifying info
    # to track a unique record
    rowid_to_column(., "index")
  
  
  # Remove fails ------------------------------------------------------------
  
  sdd_fails_removed <- raw_sdd %>%
    filter(
      # REMOVE failure-related field comments, slightly different list of words
      # than lab and result list (not including things that could be used
      # to describe field conditions like "warm", "ice", etc.)
      !grepl(
        pattern = paste0(
          c("fail", "suspect", "error", "beyond accept", "interference",
            "questionable", "outside of accept", "problem", "contaminat",
            "improper", "violation", "invalid", "unable", "no test", "cancelled",
            "instrument down", "no result", "time exceed", "not accept",
            "QC EXCEEDED"),
          collapse = "|"),
        x = field_comments,
        ignore.case = T
      ) |
        is.na(field_comments),
      # Remove failure-related lab (What about controls comments?):
      !grepl(
        pattern = paste0(
          c("fail", "suspect", "error", "beyond accept", "interference",
            "questionable", "outside of accept", "problem", "contaminat",
            "improper", "warm", "violation", "invalid", "unable", "no test",
            "cancelled", "instrument down", "no result", "time exceed",
            "not accept", "QC EXCEEDED", "not ice", "ice melt",
            "PAST HOLDING TIME", "beyond", "exceeded", "failed", "exceededs"),
          collapse = "|"),
        x = lab_comments,
        ignore.case = T
      ) |
        is.na(lab_comments),
      # Remove failure-related result comments
      !grepl(
        pattern = paste0(
          c("fail", "suspect", "error", "beyond accept", "interference",
            "questionable", "outside of accept", "problem", "contaminat",
            "improper", "warm", "violation", "invalid", "unable", "no test",
            "cancelled", "instrument down", "no result", "time exceed",
            "not accept", "QC EXCEEDED", "not ice", "ice melt",
            "PAST HOLDING TIME", "null", "unavailable", "exceeded", "rejected"),
          collapse = "|"),
        x = result_comments,
        ignore.case = T
      ) | is.na(result_comments),
      # No failure-related values
      !grepl(
        pattern = paste0(
          c("fail", "suspect", "error", "beyond accept", "interference",
            "questionable", "outside of accept", "problem", "contaminat",
            "improper", "warm", "violation", "invalid", "unable", "no test",
            "cancelled", "instrument down", "no result", "time exceed",
            "not accept", "QC EXCEEDED", "not ice", "ice melt",
            "PAST HOLDING TIME", "not done", "no reading", "no secchi",
            "not reported", "no data"),
          collapse = "|"),
        x = value,
        ignore.case = T
      ) | is.na(value))
  
  # How many records removed due to fails, missing data, etc.?
  print(
    paste0(
      "Rows removed due to fails, missing data, etc.: ",
      nrow(raw_sdd) - nrow(sdd_fails_removed)
    )
  )
  
  
  # Clean up MDLs -----------------------------------------------------------
  
  # Find MDLs and make them usable as numeric data
  mdl_updates <- sdd_fails_removed %>%
    # only want NAs and character value data:
    filter(is.na(value_numeric)) %>%
    # if the value is na BUT there is non detect language in the comments...  
    mutate(
      mdl_vals = ifelse(test = (is.na(value) & 
                                  (grepl("non-detect|not detect|non detect|undetect|below", lab_comments, ignore.case = TRUE) | 
                                     grepl("non-detect|not detect|non detect|undetect|below", result_comments, ignore.case = TRUE) |
                                     grepl("non-detect|not detect|non detect|undetect|below", ResultDetectionConditionText, ignore.case = TRUE))) |
                          #.... OR, there is non-detect language in the value column itself....
                          grepl("non-detect|not detect|non detect|undetect|below", value, ignore.case = TRUE),
                        #... use the DetectionQuantitationLimitMeasure.MeasureValue value.
                        yes = DetectionQuantitationLimitMeasure.MeasureValue,
                        # if there is a `<` and a number in the values column...
                        no = ifelse(test = grepl("[0-9]", value) & grepl("<", value),
                                    # ... use that number as the MDL
                                    yes = str_replace_all(value, c("\\<"="", "\\*" = "", "\\=" = "" )),
                                    no = NA)),
      # preserve the units if they are provided:
      mdl_units = ifelse(!is.na(mdl_vals), DetectionQuantitationLimitMeasure.MeasureUnitCode, units),
      # zero = 0,
      half = as.numeric(mdl_vals) / 2)
  
  # Using the EPA standard for non-detects, select a random number between zero and HALF the MDL:
  mdl_updates$epa_value <- with(mdl_updates, runif(nrow(mdl_updates), 0, half))
  mdl_updates$epa_value[is.nan(mdl_updates$epa_value)] <- NA
  
  # Keep important data
  mdl_updates <- mdl_updates %>%
    select(index, epa_value, mdl_vals, mdl_units) %>%
    filter(!is.na(epa_value))
  
  
  print(
    paste(
      round((nrow(mdl_updates)) / nrow(sdd_fails_removed) * 100, 1),
      '% of samples had values listed as being below a detection limit'
    )
  )
  
  # Replace "harmonized_value" field with these new values
  sdd_mdls_added <- sdd_fails_removed %>%
    left_join(x = ., y = mdl_updates, by = "index") %>%
    mutate(harmonized_value = ifelse(index %in% mdl_updates$index, epa_value, value_numeric),
           harmonized_units = ifelse(index %in% mdl_updates$index, mdl_units, units),
           harmonized_comments = ifelse(index %in% mdl_updates$index,
                                        "Approximated using the EPA's MDL method.", NA))
  
  
  # Clean up approximated values --------------------------------------------
  
  # Next step, incorporating and flagging "approximated" values. Using a similar
  # approach to our MDL detection, we can identify value fields that are labelled
  # as being approximated.
  
  sdd_approx <- sdd_mdls_added %>%
    # First, remove the samples that we've already approximated using the EPA method:
    filter(!index %in% mdl_updates$index,
           # Then select fields where the numeric value column is NA....
           is.na(value_numeric) & 
             # ... AND the original value column has numeric characters...
             grepl("[0-9]", value) &
             # ...AND any of the comment fields have approximation language...
             (grepl("result approx|RESULT IS APPROX|value approx", lab_comments, ignore.case = T)|
                grepl("result approx|RESULT IS APPROX|value approx", result_comments, ignore.case = T )|
                grepl("result approx|RESULT IS APPROX|value approx", ResultDetectionConditionText, ignore.case = T)))
  
  sdd_approx$approx_value <- as.numeric(str_replace_all(sdd_approx$value, c("\\*" = "")))
  sdd_approx$approx_value[is.nan(sdd_approx$approx_value)] <- NA
  
  # Keep important data
  sdd_approx <- sdd_approx %>%
    select(approx_value, index)
  
  print(
    paste(
      round((nrow(sdd_approx)) / nrow(sdd_mdls_added) * 100, 3),
      '% of samples had values listed as approximated'
    )
  )
  
  # Replace harmonized_value field with these new values
  sdd_approx_added <- sdd_mdls_added %>%
    left_join(x = ., y = sdd_approx, by = "index") %>%
    mutate(harmonized_value = ifelse(index %in% sdd_approx$index,
                                     approx_value,
                                     harmonized_value),
           harmonized_comments = ifelse(index %in% sdd_approx$index,
                                        'Value identified as "approximated" by organization.',
                                        harmonized_comments))
  
  
  # Clean up "greater than" values ------------------------------------------
  
  greater_vals <- sdd_approx_added %>%
    filter((!index %in% mdl_updates$index) & (!index %in% sdd_approx$index)) %>%
    # Then select fields where the NUMERIC value column is NA....
    filter(is.na(value_numeric) & 
             # ... AND the original value column has numeric characters...
             grepl("[0-9]", value) &
             #... AND a `>` symbol
             grepl(">", value))
  
  greater_vals$greater_value <- as.numeric(str_replace_all(greater_vals$value,
                                                           c("\\>" = "", "\\*" = "", "\\=" = "" )))
  greater_vals$greater_value[is.nan(greater_vals$greater_value)] <- NA
  
  # Keep important data
  greater_vals <- greater_vals %>%
    select(greater_value, index)
  
  print(
    paste(
      round((nrow(greater_vals)) / nrow(sdd_approx_added) * 100, 9),
      '% of samples had values listed as being above a detection limit//greater than'
    )
  )
  
  # Replace harmonized_value field with these new values
  sdd_harmonized_values <- sdd_approx_added %>%
    left_join(x = ., y = greater_vals, by = "index") %>%
    mutate(harmonized_value = ifelse(index %in% greater_vals$index,
                                     greater_value, harmonized_value),
           harmonized_comments = ifelse(index %in% greater_vals$index,
                                        'Value identified as being greater than listed value.',
                                        harmonized_comments))
  
  # Free up memory
  rm(raw_sdd)
  gc()
  
  
  # Harmonize value units ---------------------------------------------------
  
  # Now count the units column: 
  unit_counts <- sdd_harmonized_values %>%
    count(units) %>%
    arrange(desc(n))
  
  unit_conversion_table <- tibble(
    units = c("m", "ft", "cm", "in", "mm", "mi"),
    conversion = c(1, 0.3048, 0.01, 0.0254, 0.001, 1609.34)
  )
  
  converted_units_sdd <- sdd_harmonized_values %>%
    inner_join(x = .,
               y = unit_conversion_table,
               by = "units") %>%
    mutate(harmonized_parameter = "chl.a",
           harmonized_value = value_numeric * conversion,
           harmonized_unit = "m") %>%
    # Limit based on theoretical maximum depth
    # https://www.nalms.org/secchidipin/monitoring-methods/the-secchi-disk/secchi-records/
    filter(abs(harmonized_value) <= 80)
  
  # How many records removed due to unit harmonization?
  print(
    paste0(
      "Rows removed while converting to numeric values: ",
      nrow(sdd_harmonized_values) - nrow(converted_units_sdd)
    )
  )
  
  
  # Aggregate analytical methods --------------------------------------------
  
  # Get an idea of how many analytical methods exist:
  print(
    paste0(
      "Number of secchi analytical methods present: ",
      length(unique(converted_units_sdd$analytical_method))
    )
  )
  
  analytical_counts <- converted_units_sdd %>%
    count(analytical_method) %>%
    arrange(desc(n))
  
  # Add a new column aggregating the analytical methods groups
  grouped_analytical_methods_sdd <- converted_units_sdd %>%
    left_join(x = .,
              y = sdd_analytical_method_matchup,
              by = c("analytical_method")) %>%
    filter(analytical_method_grouping != "unlikely")
  
  # How many records removed due to limits on analytical method?
  print(
    paste0(
      "Rows removed due to unlikely analytical methods: ",
      nrow(converted_units_sdd) - nrow(grouped_analytical_methods_sdd)
    )
  )
  
  
  # Filter fractions --------------------------------------------------------
  
  # Now count the fraction column (the ungrouped version): 
  fraction_counts <- grouped_analytical_methods_sdd %>%
    count(fraction) %>%
    arrange(desc(n))
  
  # Create a column to lump things that do/don't make sense for the fraction column
  grouped_fractions_sdd <- grouped_analytical_methods_sdd %>%
    mutate(aquasat_fraction = if_else(
      condition = fraction %in% c(NA, "Total", " ", "None", "Unfiltered", "Field"),
      true = "Makes sense",
      false = "Nonsensical")) %>%
    filter(aquasat_fraction == "Makes sense")
  
  # How many records removed due to unlikely fraction types?
  print(
    paste0(
      "Rows removed due to unlikely fraction type: ",
      nrow(grouped_analytical_methods_sdd) - nrow(grouped_fractions_sdd)
    )
  )
  
  
  # Aggregate sample methods ------------------------------------------------
  
  # # Now count the sample_method column: 
  # sample_counts <- grouped_fractions_sdd %>%
  #   count(sample_method) %>%
  #   arrange(desc(n))
  # 
  # # Add a new column describing the sample_method group:
  # grouped_sample_methods_sdd <- grouped_fractions_sdd %>%
  #   left_join(x = .,
  #             y = sdd_sample_method_matchup,
  #             by = c("sample_method")) %>%
  #   filter(sample_method_grouping != "unlikely")
  # 
  # # How many records removed due to unlikely sample methods?
  # print(
  #   paste0(
  #     "Rows removed due to unlikely sample methods: ",
  #     nrow(grouped_fractions_sdd) - nrow(grouped_sample_methods_sdd)
  #   )
  # )
  
  grouped_sample_methods_sdd <- grouped_fractions_sdd
  
  
  # Aggregate collection equipment ------------------------------------------
  
  # # Now count the collection_equipment column:
  # equipment_counts <- grouped_sample_methods_sdd %>%
  #   count(collection_equipment) %>%
  #   arrange(desc(n))
  # 
  # grouped_equipment_sdd <- grouped_sample_methods_sdd %>%
  #   left_join(x = .,
  #             y = sdd_equipment_matchup,
  #             by = c("collection_equipment")) %>%
  #   filter(equipment_grouping != "unlikely")
  # 
  # # How many records removed due to unlikely sample methods?
  # print(
  #   paste0(
  #     "Rows removed due to unlikely sample methods: ",
  #     nrow(grouped_sample_methods_sdd) - nrow(grouped_equipment_sdd)
  #   )
  # )
  
  grouped_equipment_sdd <- grouped_sample_methods_sdd
  
  
  # Export ------------------------------------------------------------------
  
  # Export in memory-friendly way
  data_out_path <- "3_harmonize/out/harmonized_sdd.feather"
  
  write_feather(grouped_equipment_sdd,
                data_out_path)
  
  # Final dataset length:
  print(
    paste0(
      "Final number of records: ",
      nrow(grouped_equipment_sdd)
    )
  )
  
  return(data_out_path)
  
}